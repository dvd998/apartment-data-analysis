{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Preprocessing\n",
    "\n",
    "This cell performs the initial data extraction and preprocessing steps necessary for building machine learning models.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Library Imports**: We import required libraries including pandas for data manipulation, KNeighborsClassifier, RandomForestClassifier, and SVC for building machine learning models, and StandardScaler for feature scaling.\n",
    "\n",
    "2. **Data Loading**: We load the dataset from an Excel file (`Processed data combined.xlsx`) into a pandas DataFrame (`df`).\n",
    "\n",
    "3. **Feature Engineering**: We create a new feature `room_groups` based on the `room_number` column. This feature categorizes the number of rooms into groups ('<2.5', '<4.5', '4.5+').\n",
    "\n",
    "4. **Train-Test Split**: We split the dataset into training and testing sets using the `train_test_split` function. The training set contains 75% of the data (`train_values`, `train_labels`), while the testing set contains 25% (`test_values`, `test_labels`).\n",
    "\n",
    "5. **Feature Scaling**: We standardize the features using `StandardScaler` to ensure all features have the same scale, which is important for many machine learning algorithms.\n",
    "\n",
    "### Variables:\n",
    "\n",
    "- **df**: Pandas DataFrame containing the dataset.\n",
    "- **values**: List of feature values (`price` and `sq_meters`).\n",
    "- **labels**: List of target labels (`room_groups`).\n",
    "- **train_values**, **test_values**: Feature values for training and testing.\n",
    "- **train_labels**, **test_labels**: Target labels for training and testing.\n",
    "- **scaler**: StandardScaler object used for feature scaling.\n",
    "- **train_values_scaled**, **test_values_scaled**: Scaled feature values for training and testing.\n",
    "\n",
    "By completing these preprocessing steps, we prepare the dataset for model training and evaluation, ensuring that the features are appropriately scaled and the data is split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Data extraction and preparing train and test data sets\n",
    "df = pd.read_excel('Excel_files\\\\Processed data combined.xlsx')\n",
    "df['room_groups'] = df['room_number'].apply(lambda x: '<2.5' if x < 2.5 else ('<4.5' if x < 4.5 else '4.5+'))\n",
    "values = df[['price', 'sq_meters']].values.tolist()\n",
    "labels = list(df['room_groups'])\n",
    "train_values, test_values, train_labels, test_labels = train_test_split(values, labels, test_size=0.25)\n",
    "scaler = StandardScaler()\n",
    "train_values_scaled = scaler.fit_transform(train_values)\n",
    "test_values_scaled = scaler.fit_transform(test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN) Model Training\n",
    "\n",
    "In this cell, we use the k-nearest neighbors algorithm to predict the room number category based on the provided features.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Parameter Grid Definition**: We define a parameter grid (`param_grid_knear`) specifying the range of `n_neighbors` hyperparameter values to be explored during hyperparameter tuning.\n",
    "\n",
    "2. **Model Initialization**: We initialize a KNeighborsClassifier (`knear_classifier`) with default parameters.\n",
    "\n",
    "3. **Grid Search Cross Validation**: We perform grid search cross-validation using GridSearchCV to find the best combination of hyperparameters for the KNN model. The grid search is conducted with 5-fold cross-validation (`cv=5`) and using accuracy as the scoring metric.\n",
    "\n",
    "4. **Best Parameters and Accuracy**: After completing grid search cross-validation, we retrieve the best parameters (`best_params`) and the corresponding accuracy (`best_accuracy`) achieved by the model on the training data.\n",
    "\n",
    "### Results:\n",
    "\n",
    "- **Best Parameters**: The optimal value of the `n_neighbors` hyperparameter obtained through grid search cross-validation.\n",
    "  \n",
    "- **Best Accuracy**: The accuracy achieved by the model with the best parameters on the training data.\n",
    "\n",
    "By leveraging grid search cross-validation, we identify the best hyperparameters for the KNN model, optimizing its performance for predicting room numbers based on the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 33}\n",
      "Best Accuracy: 0.8585858585858587\n"
     ]
    }
   ],
   "source": [
    "param_grid_knear = {'n_neighbors': range(25, 150)}\n",
    "knear_classifier = KNeighborsClassifier()\n",
    "\n",
    "grid_search_knear = GridSearchCV(knear_classifier, param_grid_knear, cv=5, scoring='accuracy')\n",
    "grid_search_knear.fit(train_values_scaled, train_labels)\n",
    "\n",
    "best_params = grid_search_knear.best_params_\n",
    "best_accuracy = grid_search_knear.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Training\n",
    "\n",
    "In this cell, we utilize the random forest algorithm to predict the room number category based on the provided features.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Parameter Grid Definition**: We define a parameter grid (`param_grid_rforest`) specifying the range of `n_estimators` hyperparameter values to be explored during hyperparameter tuning.\n",
    "\n",
    "2. **Model Initialization**: We initialize a RandomForestClassifier (`rforest_classifier`) with default parameters.\n",
    "\n",
    "3. **Grid Search Cross Validation**: We perform grid search cross-validation using GridSearchCV to find the best combination of hyperparameters for the random forest model. The grid search is conducted with 5-fold cross-validation (`cv=5`) and using accuracy as the scoring metric.\n",
    "\n",
    "4. **Best Parameters and Accuracy**: After completing grid search cross-validation, we retrieve the best parameters (`best_params_rforest`) and the corresponding accuracy (`best_accuracy_rforest`) achieved by the model on the training data.\n",
    "\n",
    "### Results:\n",
    "\n",
    "- **Best Parameters**: The optimal value of the `n_estimators` hyperparameter obtained through grid search cross-validation.\n",
    "  \n",
    "- **Best Accuracy**: The accuracy achieved by the model with the best parameters on the training data.\n",
    "\n",
    "By leveraging grid search cross-validation, we identify the best hyperparameters for the random forest model, optimizing its performance for predicting room numbers based on the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 200}\n",
      "Best Accuracy: 0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "param_grid_rforest = {'n_estimators': range(100, 1500, 100)}\n",
    "\n",
    "rforest_classifier = RandomForestClassifier()\n",
    "\n",
    "grid_search_rforest = GridSearchCV(rforest_classifier, param_grid_rforest, cv=5, scoring='accuracy')\n",
    "grid_search_rforest.fit(train_values_scaled, train_labels)\n",
    "\n",
    "best_params_rforest = grid_search_rforest.best_params_\n",
    "best_accuracy_rforest = grid_search_rforest.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params_rforest)\n",
    "print(\"Best Accuracy:\", best_accuracy_rforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) Model Training\n",
    "\n",
    "In this cell, we employ the support vector machine (SVM) algorithm to predict the room number category based on the provided features.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Parameter Grid Definition**: We define a parameter grid (`param_grid_svm`) specifying the range of hyperparameters (`C`, `gamma`, `kernel`) to be explored during hyperparameter tuning.\n",
    "\n",
    "2. **Model Initialization**: We initialize an SVC (Support Vector Classifier) (`svm_classifier`) with default parameters.\n",
    "\n",
    "3. **Grid Search Cross Validation**: We perform grid search cross-validation using GridSearchCV to find the best combination of hyperparameters for the SVM model. The grid search is conducted with 5-fold cross-validation (`cv=5`) and using accuracy as the scoring metric.\n",
    "\n",
    "4. **Best Parameters and Accuracy**: After completing grid search cross-validation, we retrieve the best parameters (`best_params_svm`) and the corresponding accuracy (`best_accuracy_svm`) achieved by the model on the training data.\n",
    "\n",
    "### Results:\n",
    "\n",
    "- **Best Parameters**: The optimal values of the hyperparameters (`C`, `gamma`, `kernel`) obtained through grid search cross-validation.\n",
    "  \n",
    "- **Best Accuracy**: The accuracy achieved by the model with the best parameters on the training data.\n",
    "\n",
    "By leveraging grid search cross-validation, we identify the best hyperparameters for the SVM model, optimizing its performance for predicting room numbers based on the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "Best Accuracy: 0.8666666666666668\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(train_values_scaled, train_labels)\n",
    "\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_accuracy_svm = grid_search_svm.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params_svm)\n",
    "print(\"Best Accuracy:\", best_accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the use of three different supervised classification machine learning algorithms—K-Nearest Neighbors (KNN), Random Forest, and Support Vector Machine (SVM)—to predict room numbers based on features extracted from a dataset.\n",
    "\n",
    "After thorough preprocessing, including data extraction, feature engineering, and scaling, we trained each model using grid search cross-validation to find the optimal hyperparameters. \n",
    "\n",
    "The results obtained from the cross-validation process revealed that all three models performed similarly, with accuracies ranging between 0.83 and 0.86 on the training data. The optimal hyperparameters for each model were determined as follows:\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**: Optimal number of neighbors: 33.\n",
    "  \n",
    "- **Random Forest**: Optimal number of estimators: 200.\n",
    "  \n",
    "- **Support Vector Machine (SVM)**: Optimal parameters: 'C': 1, 'gamma': 1, 'kernel': 'linear'.\n",
    "\n",
    "Further evaluation on a separate test set is necessary to validate the performance of each model on unseen data.\n",
    "\n",
    "In conclusion, all three models show promising results for predicting room numbers based on the provided features. Depending on the specific requirements and constraints of the problem, one can choose any of the models for deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
